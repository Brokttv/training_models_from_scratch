
## Training Large Language Models from First Principles â€” Using Math and NumPy Only

This project explores the training of large language models (LLMs) entirely from first principles, using only core mathematical operations and NumPy â€” without the aid of any deep learning frameworks.  
The goal is to offer both a practical and conceptual understanding of how LLMs work at the lowest level of abstraction.

---

### âœ… Why Take This Approach?

- ðŸ§  Develop a **deep, intuitive grasp** of the underlying mechanisms of neural networks and optimization.
- âš™ï¸ Understand the **mathematical foundations** that power modern machine learning frameworks such as PyTorch and TensorFlow.
- ðŸ” Mastering NumPy lays a strong groundwork for transitioning to higher-level tools â€” the syntax and logic are remarkably similar.
- ðŸ› ï¸ Gain the ability to **debug models intelligently**, having built every layer from scratch and observed their behavior at a granular level.

---

## ðŸš€ Project Framework

All components are implemented using:
- ðŸ **Python**
- ðŸ§® **NumPy**
- âŒ No high-level machine learning libraries

This is a hands-on, code-first exploration designed to expose the mathematical anatomy of LLMs through implementation.

---

## ðŸ—‚ï¸ Learning Roadmap

### ðŸ”¹ Part 1: Foundations â€” Linear and Logistic Regression

We begin with fundamental supervised learning algorithms to build intuition:
- A **one-dimensional linear regression** model  
- A **single-neuron logistic regression** model for binary classification

> ðŸ’¡ **Need additional support?**  
> Refer to [this excellent YouTube playlist](https://youtube.com/playlist?list=PLeM4O8deP8GO3vIx_9eboO9tVpUKHYqRg&si=_qPsNeX3TuMZS9sf) by Professor Bryce for an in-depth visual guide.

<br>

**Mathematical Implementation Overview:**

<div align="center">
  <img src="Untitled design (18).png" alt="Linear and Logistic Regression" width="900">
</div>

---

### ðŸ”¸ Part 2: Neural Networks from Scratch

We then extend our models to multi-layer neural networks:
- A **single-input, two-layer fully connected neural network**
- A **multi-input variant**, capable of handling vectorized features
- All focused on **regression tasks**, enabling visual interpretability of outputs

This section highlights:
- The role and necessity of **non-linear activation functions**
- How simple mathematical constructs are composed to achieve sophisticated model behavior

#### ðŸ§  Single-Input Neural Network

<div align="center">
  <img src="Untitled design (16).png" alt="Single Input Neural Network" width="700">
</div>

#### ðŸ§  Multi-Input Neural Network

<div align="center">
  <img src="Untitled design (17).png" alt="Multiple Input Neural Network">
</div>


